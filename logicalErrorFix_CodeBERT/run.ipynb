{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1V_IUmFCiCVNOr950LzIgeQBNI3wgNO1S","authorship_tag":"ABX9TyOFiniHBgD2gjgWBwNA0E2w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!bash"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eB3d4hp-EwLv","outputId":"55132f80-ec5f-4b5c-9427-1bd6ad03fef3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bash: cannot set terminal process group (461): Inappropriate ioctl for device\n","bash: no job control in this shell\n","\u001b[?2004h\u001b[01;34m/content\u001b[00m# cd /content/drive/MyDrive/logicalErrorFix-1\n","\u001b[?2004h\u001b[01;34m/content/drive/MyDrive/logicalErrorFix-1\u001b[00m# bash train.sh\n","02/22/2024 04:58:50 - INFO - numexpr.utils -   NumExpr defaulting to 2 threads.\n","02/22/2024 04:58:50 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/cpp', load_model_path=None, train_filename='./data/edit_distance/pair_code_edit_dist_train.txt', dev_filename='./data/edit_distance/pair_code_edit_dist_valid.txt', test_filename=None, config_name='', tokenizer_name='', max_source_length=512, max_target_length=64, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=16, eval_batch_size=16, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=1000, train_steps=50000, warmup_steps=0, local_rank=-1, seed=42)\n","02/22/2024 04:58:50 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n","config.json: 100% 498/498 [00:00<00:00, 1.84MB/s]\n","tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 140kB/s]\n","vocab.json: 100% 899k/899k [00:00<00:00, 17.9MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 19.7MB/s]\n","special_tokens_map.json: 100% 150/150 [00:00<00:00, 867kB/s]\n","pytorch_model.bin: 100% 499M/499M [00:03<00:00, 148MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","02/22/2024 05:00:52 - INFO - __main__ -   ***** Running training *****\n","02/22/2024 05:00:52 - INFO - __main__ -     Num examples = 56051\n","02/22/2024 05:00:52 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:00:52 - INFO - __main__ -     Num epoch = 14\n","loss 2.841:   2% 998/50000 [09:04<7:25:00,  1.84it/s] 02/22/2024 05:09:58 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 05:09:58 - INFO - __main__ -     Num examples = 580\n","02/22/2024 05:09:58 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:10:05 - INFO - __main__ -     eval_ppl = 9.79517\n","02/22/2024 05:10:05 - INFO - __main__ -     global_step = 1000\n","02/22/2024 05:10:05 - INFO - __main__ -     train_loss = 2.841\n","02/22/2024 05:10:05 - INFO - __main__ -     ********************\n","02/22/2024 05:10:17 - INFO - __main__ -     Best ppl:9.79517\n","02/22/2024 05:10:17 - INFO - __main__ -     ********************\n","/content/drive/MyDrive/logicalErrorFix-1/model.py:77: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  zero=torch.cuda.LongTensor(1).fill_(0)\n","2024-02-22 05:10:36.595193: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-22 05:10:36.595268: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-22 05:10:36.597301: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-22 05:10:38.588186: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Total: 580\n","02/22/2024 05:12:33 - INFO - __main__ -     bleu-4 = 11.89 \n","02/22/2024 05:12:33 - INFO - __main__ -     ********************\n","02/22/2024 05:12:33 - INFO - __main__ -     Best bleu:11.89\n","02/22/2024 05:12:33 - INFO - __main__ -     ********************\n","loss 2.1956:   4% 1998/50000 [20:59<7:17:41,  1.83it/s]02/22/2024 05:21:52 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 05:21:52 - INFO - __main__ -     Num examples = 580\n","02/22/2024 05:21:52 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:21:58 - INFO - __main__ -     eval_ppl = 7.48459\n","02/22/2024 05:21:58 - INFO - __main__ -     global_step = 2000\n","02/22/2024 05:21:58 - INFO - __main__ -     train_loss = 2.1956\n","02/22/2024 05:21:58 - INFO - __main__ -     ********************\n","02/22/2024 05:22:01 - INFO - __main__ -     Best ppl:7.48459\n","02/22/2024 05:22:01 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 05:24:41 - INFO - __main__ -     bleu-4 = 12.31 \n","02/22/2024 05:24:41 - INFO - __main__ -     ********************\n","02/22/2024 05:24:41 - INFO - __main__ -     Best bleu:12.31\n","02/22/2024 05:24:41 - INFO - __main__ -     ********************\n","loss 1.9505:   6% 2998/50000 [32:56<7:07:04,  1.83it/s]02/22/2024 05:33:49 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 05:33:49 - INFO - __main__ -     Num examples = 580\n","02/22/2024 05:33:49 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:33:56 - INFO - __main__ -     eval_ppl = 5.52888\n","02/22/2024 05:33:56 - INFO - __main__ -     global_step = 3000\n","02/22/2024 05:33:56 - INFO - __main__ -     train_loss = 1.9505\n","02/22/2024 05:33:56 - INFO - __main__ -     ********************\n","02/22/2024 05:33:59 - INFO - __main__ -     Best ppl:5.52888\n","02/22/2024 05:33:59 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 05:36:23 - INFO - __main__ -     bleu-4 = 15.81 \n","02/22/2024 05:36:23 - INFO - __main__ -     ********************\n","02/22/2024 05:36:23 - INFO - __main__ -     Best bleu:15.81\n","02/22/2024 05:36:23 - INFO - __main__ -     ********************\n","loss 1.6478:   8% 3998/50000 [44:37<6:56:42,  1.84it/s]02/22/2024 05:45:30 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 05:45:30 - INFO - __main__ -     Num examples = 580\n","02/22/2024 05:45:30 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:45:37 - INFO - __main__ -     eval_ppl = 4.42399\n","02/22/2024 05:45:37 - INFO - __main__ -     global_step = 4000\n","02/22/2024 05:45:37 - INFO - __main__ -     train_loss = 1.6478\n","02/22/2024 05:45:37 - INFO - __main__ -     ********************\n","02/22/2024 05:45:42 - INFO - __main__ -     Best ppl:4.42399\n","02/22/2024 05:45:42 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 05:48:19 - INFO - __main__ -     bleu-4 = 17.82 \n","02/22/2024 05:48:19 - INFO - __main__ -     ********************\n","02/22/2024 05:48:19 - INFO - __main__ -     Best bleu:17.82\n","02/22/2024 05:48:19 - INFO - __main__ -     ********************\n","loss 1.3642:  10% 4998/50000 [56:38<6:52:40,  1.82it/s]02/22/2024 05:57:31 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 05:57:31 - INFO - __main__ -     Num examples = 580\n","02/22/2024 05:57:31 - INFO - __main__ -     Batch size = 16\n","02/22/2024 05:57:37 - INFO - __main__ -     eval_ppl = 3.58281\n","02/22/2024 05:57:37 - INFO - __main__ -     global_step = 5000\n","02/22/2024 05:57:37 - INFO - __main__ -     train_loss = 1.3642\n","02/22/2024 05:57:37 - INFO - __main__ -     ********************\n","02/22/2024 05:57:43 - INFO - __main__ -     Best ppl:3.58281\n","02/22/2024 05:57:43 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 06:00:39 - INFO - __main__ -     bleu-4 = 13.96 \n","02/22/2024 06:00:39 - INFO - __main__ -     ********************\n","loss 1.2134:  12% 5998/50000 [1:08:51<6:39:06,  1.84it/s]02/22/2024 06:09:44 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 06:09:44 - INFO - __main__ -     Num examples = 580\n","02/22/2024 06:09:44 - INFO - __main__ -     Batch size = 16\n","02/22/2024 06:09:51 - INFO - __main__ -     eval_ppl = 3.17296\n","02/22/2024 06:09:51 - INFO - __main__ -     global_step = 6000\n","02/22/2024 06:09:51 - INFO - __main__ -     train_loss = 1.2134\n","02/22/2024 06:09:51 - INFO - __main__ -     ********************\n","02/22/2024 06:09:58 - INFO - __main__ -     Best ppl:3.17296\n","02/22/2024 06:09:58 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 06:12:36 - INFO - __main__ -     bleu-4 = 16.34 \n","02/22/2024 06:12:36 - INFO - __main__ -     ********************\n","loss 1.1046:  14% 6998/50000 [1:20:49<6:33:02,  1.82it/s]02/22/2024 06:21:42 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 06:21:42 - INFO - __main__ -     Num examples = 580\n","02/22/2024 06:21:42 - INFO - __main__ -     Batch size = 16\n","02/22/2024 06:21:48 - INFO - __main__ -     eval_ppl = 2.9686\n","02/22/2024 06:21:48 - INFO - __main__ -     global_step = 7000\n","02/22/2024 06:21:48 - INFO - __main__ -     train_loss = 1.1046\n","02/22/2024 06:21:48 - INFO - __main__ -     ********************\n","02/22/2024 06:21:51 - INFO - __main__ -     Best ppl:2.9686\n","02/22/2024 06:21:51 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 06:24:41 - INFO - __main__ -     bleu-4 = 17.21 \n","02/22/2024 06:24:41 - INFO - __main__ -     ********************\n","loss 0.9958:  16% 7998/50000 [1:32:52<6:20:12,  1.84it/s]02/22/2024 06:33:45 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 06:33:45 - INFO - __main__ -     Num examples = 580\n","02/22/2024 06:33:45 - INFO - __main__ -     Batch size = 16\n","02/22/2024 06:33:51 - INFO - __main__ -     eval_ppl = 2.90564\n","02/22/2024 06:33:51 - INFO - __main__ -     global_step = 8000\n","02/22/2024 06:33:51 - INFO - __main__ -     train_loss = 0.9958\n","02/22/2024 06:33:51 - INFO - __main__ -     ********************\n","02/22/2024 06:33:54 - INFO - __main__ -     Best ppl:2.90564\n","02/22/2024 06:33:54 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 06:36:33 - INFO - __main__ -     bleu-4 = 18.94 \n","02/22/2024 06:36:33 - INFO - __main__ -     ********************\n","02/22/2024 06:36:33 - INFO - __main__ -     Best bleu:18.94\n","02/22/2024 06:36:33 - INFO - __main__ -     ********************\n","loss 0.939:  18% 8998/50000 [1:44:55<6:13:17,  1.83it/s] 02/22/2024 06:45:48 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 06:45:48 - INFO - __main__ -     Num examples = 580\n","02/22/2024 06:45:48 - INFO - __main__ -     Batch size = 16\n","02/22/2024 06:45:54 - INFO - __main__ -     eval_ppl = 2.77603\n","02/22/2024 06:45:54 - INFO - __main__ -     global_step = 9000\n","02/22/2024 06:45:54 - INFO - __main__ -     train_loss = 0.939\n","02/22/2024 06:45:54 - INFO - __main__ -     ********************\n","02/22/2024 06:46:01 - INFO - __main__ -     Best ppl:2.77603\n","02/22/2024 06:46:01 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 06:48:48 - INFO - __main__ -     bleu-4 = 17.51 \n","02/22/2024 06:48:48 - INFO - __main__ -     ********************\n","loss 0.8928:  20% 9998/50000 [1:57:00<6:02:13,  1.84it/s]02/22/2024 06:57:53 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 06:57:53 - INFO - __main__ -     Num examples = 580\n","02/22/2024 06:57:53 - INFO - __main__ -     Batch size = 16\n","02/22/2024 06:57:59 - INFO - __main__ -     eval_ppl = 2.6889\n","02/22/2024 06:57:59 - INFO - __main__ -     global_step = 10000\n","02/22/2024 06:57:59 - INFO - __main__ -     train_loss = 0.8928\n","02/22/2024 06:57:59 - INFO - __main__ -     ********************\n","02/22/2024 06:58:02 - INFO - __main__ -     Best ppl:2.6889\n","02/22/2024 06:58:02 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 07:00:52 - INFO - __main__ -     bleu-4 = 19.0 \n","02/22/2024 07:00:52 - INFO - __main__ -     ********************\n","02/22/2024 07:00:52 - INFO - __main__ -     Best bleu:19.0\n","02/22/2024 07:00:52 - INFO - __main__ -     ********************\n","loss 0.8341:  22% 10998/50000 [2:09:08<5:54:14,  1.84it/s]02/22/2024 07:10:01 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 07:10:01 - INFO - __main__ -     Num examples = 580\n","02/22/2024 07:10:01 - INFO - __main__ -     Batch size = 16\n","02/22/2024 07:10:07 - INFO - __main__ -     eval_ppl = 2.58856\n","02/22/2024 07:10:07 - INFO - __main__ -     global_step = 11000\n","02/22/2024 07:10:07 - INFO - __main__ -     train_loss = 0.8341\n","02/22/2024 07:10:07 - INFO - __main__ -     ********************\n","02/22/2024 07:10:10 - INFO - __main__ -     Best ppl:2.58856\n","02/22/2024 07:10:10 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 07:12:48 - INFO - __main__ -     bleu-4 = 20.02 \n","02/22/2024 07:12:48 - INFO - __main__ -     ********************\n","02/22/2024 07:12:48 - INFO - __main__ -     Best bleu:20.02\n","02/22/2024 07:12:48 - INFO - __main__ -     ********************\n","loss 0.7676:  24% 11998/50000 [2:21:03<5:43:46,  1.84it/s]02/22/2024 07:21:56 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 07:21:56 - INFO - __main__ -     Num examples = 580\n","02/22/2024 07:21:56 - INFO - __main__ -     Batch size = 16\n","02/22/2024 07:22:02 - INFO - __main__ -     eval_ppl = 2.55848\n","02/22/2024 07:22:02 - INFO - __main__ -     global_step = 12000\n","02/22/2024 07:22:02 - INFO - __main__ -     train_loss = 0.7676\n","02/22/2024 07:22:02 - INFO - __main__ -     ********************\n","02/22/2024 07:22:06 - INFO - __main__ -     Best ppl:2.55848\n","02/22/2024 07:22:06 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 07:24:54 - INFO - __main__ -     bleu-4 = 19.96 \n","02/22/2024 07:24:54 - INFO - __main__ -     ********************\n","loss 0.7515:  26% 12998/50000 [2:33:06<5:36:26,  1.83it/s]02/22/2024 07:33:59 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 07:33:59 - INFO - __main__ -     Num examples = 580\n","02/22/2024 07:33:59 - INFO - __main__ -     Batch size = 16\n","02/22/2024 07:34:06 - INFO - __main__ -     eval_ppl = 2.537\n","02/22/2024 07:34:06 - INFO - __main__ -     global_step = 13000\n","02/22/2024 07:34:06 - INFO - __main__ -     train_loss = 0.7515\n","02/22/2024 07:34:06 - INFO - __main__ -     ********************\n","02/22/2024 07:34:16 - INFO - __main__ -     Best ppl:2.537\n","02/22/2024 07:34:16 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 07:37:07 - INFO - __main__ -     bleu-4 = 20.19 \n","02/22/2024 07:37:07 - INFO - __main__ -     ********************\n","02/22/2024 07:37:07 - INFO - __main__ -     Best bleu:20.19\n","02/22/2024 07:37:07 - INFO - __main__ -     ********************\n","loss 0.7171:  28% 13998/50000 [2:45:25<5:28:47,  1.82it/s]02/22/2024 07:46:18 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 07:46:18 - INFO - __main__ -     Num examples = 580\n","02/22/2024 07:46:18 - INFO - __main__ -     Batch size = 16\n","02/22/2024 07:46:24 - INFO - __main__ -     eval_ppl = 2.5329\n","02/22/2024 07:46:24 - INFO - __main__ -     global_step = 14000\n","02/22/2024 07:46:24 - INFO - __main__ -     train_loss = 0.7171\n","02/22/2024 07:46:24 - INFO - __main__ -     ********************\n","02/22/2024 07:46:27 - INFO - __main__ -     Best ppl:2.5329\n","02/22/2024 07:46:27 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 07:49:19 - INFO - __main__ -     bleu-4 = 21.07 \n","02/22/2024 07:49:19 - INFO - __main__ -     ********************\n","02/22/2024 07:49:19 - INFO - __main__ -     Best bleu:21.07\n","02/22/2024 07:49:19 - INFO - __main__ -     ********************\n","loss 0.6717:  30% 14998/50000 [2:57:35<5:19:05,  1.83it/s]02/22/2024 07:58:28 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 07:58:28 - INFO - __main__ -     Num examples = 580\n","02/22/2024 07:58:28 - INFO - __main__ -     Batch size = 16\n","02/22/2024 07:58:34 - INFO - __main__ -     eval_ppl = 2.5231\n","02/22/2024 07:58:34 - INFO - __main__ -     global_step = 15000\n","02/22/2024 07:58:34 - INFO - __main__ -     train_loss = 0.6717\n","02/22/2024 07:58:34 - INFO - __main__ -     ********************\n","02/22/2024 07:58:37 - INFO - __main__ -     Best ppl:2.5231\n","02/22/2024 07:58:37 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 08:01:19 - INFO - __main__ -     bleu-4 = 20.36 \n","02/22/2024 08:01:19 - INFO - __main__ -     ********************\n","loss 0.6501:  32% 15998/50000 [3:09:33<5:12:00,  1.82it/s]02/22/2024 08:10:26 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 08:10:26 - INFO - __main__ -     Num examples = 580\n","02/22/2024 08:10:26 - INFO - __main__ -     Batch size = 16\n","02/22/2024 08:10:32 - INFO - __main__ -     eval_ppl = 2.52349\n","02/22/2024 08:10:32 - INFO - __main__ -     global_step = 16000\n","02/22/2024 08:10:32 - INFO - __main__ -     train_loss = 0.6501\n","02/22/2024 08:10:32 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 08:13:16 - INFO - __main__ -     bleu-4 = 21.68 \n","02/22/2024 08:13:16 - INFO - __main__ -     ********************\n","02/22/2024 08:13:16 - INFO - __main__ -     Best bleu:21.68\n","02/22/2024 08:13:16 - INFO - __main__ -     ********************\n","loss 0.6297:  34% 16998/50000 [3:21:32<5:01:33,  1.82it/s]02/22/2024 08:22:25 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 08:22:25 - INFO - __main__ -     Num examples = 580\n","02/22/2024 08:22:25 - INFO - __main__ -     Batch size = 16\n","02/22/2024 08:22:31 - INFO - __main__ -     eval_ppl = 2.4567\n","02/22/2024 08:22:31 - INFO - __main__ -     global_step = 17000\n","02/22/2024 08:22:31 - INFO - __main__ -     train_loss = 0.6297\n","02/22/2024 08:22:31 - INFO - __main__ -     ********************\n","02/22/2024 08:22:34 - INFO - __main__ -     Best ppl:2.4567\n","02/22/2024 08:22:34 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 08:25:11 - INFO - __main__ -     bleu-4 = 21.02 \n","02/22/2024 08:25:11 - INFO - __main__ -     ********************\n","loss 0.6038:  36% 17998/50000 [3:33:23<4:53:13,  1.82it/s]02/22/2024 08:34:16 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 08:34:16 - INFO - __main__ -     Num examples = 580\n","02/22/2024 08:34:16 - INFO - __main__ -     Batch size = 16\n","02/22/2024 08:34:23 - INFO - __main__ -     eval_ppl = 2.48046\n","02/22/2024 08:34:23 - INFO - __main__ -     global_step = 18000\n","02/22/2024 08:34:23 - INFO - __main__ -     train_loss = 0.6038\n","02/22/2024 08:34:23 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 08:36:56 - INFO - __main__ -     bleu-4 = 22.06 \n","02/22/2024 08:36:56 - INFO - __main__ -     ********************\n","02/22/2024 08:36:56 - INFO - __main__ -     Best bleu:22.06\n","02/22/2024 08:36:56 - INFO - __main__ -     ********************\n","loss 0.5679:  38% 18998/50000 [3:45:12<4:41:46,  1.83it/s]02/22/2024 08:46:05 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 08:46:05 - INFO - __main__ -     Num examples = 580\n","02/22/2024 08:46:05 - INFO - __main__ -     Batch size = 16\n","02/22/2024 08:46:12 - INFO - __main__ -     eval_ppl = 2.47403\n","02/22/2024 08:46:12 - INFO - __main__ -     global_step = 19000\n","02/22/2024 08:46:12 - INFO - __main__ -     train_loss = 0.5679\n","02/22/2024 08:46:12 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 08:48:46 - INFO - __main__ -     bleu-4 = 20.54 \n","02/22/2024 08:48:46 - INFO - __main__ -     ********************\n","loss 0.5605:  40% 19998/50000 [3:57:00<4:32:27,  1.84it/s]02/22/2024 08:57:53 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 08:57:53 - INFO - __main__ -     Num examples = 580\n","02/22/2024 08:57:53 - INFO - __main__ -     Batch size = 16\n","02/22/2024 08:57:59 - INFO - __main__ -     eval_ppl = 2.47784\n","02/22/2024 08:57:59 - INFO - __main__ -     global_step = 20000\n","02/22/2024 08:57:59 - INFO - __main__ -     train_loss = 0.5605\n","02/22/2024 08:57:59 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 09:00:35 - INFO - __main__ -     bleu-4 = 21.0 \n","02/22/2024 09:00:35 - INFO - __main__ -     ********************\n","loss 0.54:  42% 20998/50000 [4:08:48<4:25:49,  1.82it/s]  02/22/2024 09:09:41 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 09:09:41 - INFO - __main__ -     Num examples = 580\n","02/22/2024 09:09:41 - INFO - __main__ -     Batch size = 16\n","02/22/2024 09:09:48 - INFO - __main__ -     eval_ppl = 2.45061\n","02/22/2024 09:09:48 - INFO - __main__ -     global_step = 21000\n","02/22/2024 09:09:48 - INFO - __main__ -     train_loss = 0.54\n","02/22/2024 09:09:48 - INFO - __main__ -     ********************\n","02/22/2024 09:09:50 - INFO - __main__ -     Best ppl:2.45061\n","02/22/2024 09:09:50 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 09:12:33 - INFO - __main__ -     bleu-4 = 23.79 \n","02/22/2024 09:12:33 - INFO - __main__ -     ********************\n","02/22/2024 09:12:33 - INFO - __main__ -     Best bleu:23.79\n","02/22/2024 09:12:33 - INFO - __main__ -     ********************\n","loss 0.5058:  44% 21998/50000 [4:20:54<4:14:41,  1.83it/s]02/22/2024 09:21:47 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 09:21:47 - INFO - __main__ -     Num examples = 580\n","02/22/2024 09:21:47 - INFO - __main__ -     Batch size = 16\n","02/22/2024 09:21:53 - INFO - __main__ -     eval_ppl = 2.49732\n","02/22/2024 09:21:53 - INFO - __main__ -     global_step = 22000\n","02/22/2024 09:21:53 - INFO - __main__ -     train_loss = 0.5058\n","02/22/2024 09:21:53 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 09:24:29 - INFO - __main__ -     bleu-4 = 21.26 \n","02/22/2024 09:24:29 - INFO - __main__ -     ********************\n","loss 0.4919:  46% 22998/50000 [4:32:42<4:06:36,  1.82it/s]02/22/2024 09:33:35 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 09:33:35 - INFO - __main__ -     Num examples = 580\n","02/22/2024 09:33:35 - INFO - __main__ -     Batch size = 16\n","02/22/2024 09:33:42 - INFO - __main__ -     eval_ppl = 2.46817\n","02/22/2024 09:33:42 - INFO - __main__ -     global_step = 23000\n","02/22/2024 09:33:42 - INFO - __main__ -     train_loss = 0.4919\n","02/22/2024 09:33:42 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 09:36:25 - INFO - __main__ -     bleu-4 = 22.03 \n","02/22/2024 09:36:25 - INFO - __main__ -     ********************\n","loss 0.4746:  48% 23998/50000 [4:44:39<3:56:43,  1.83it/s]02/22/2024 09:45:32 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 09:45:32 - INFO - __main__ -     Num examples = 580\n","02/22/2024 09:45:32 - INFO - __main__ -     Batch size = 16\n","02/22/2024 09:45:38 - INFO - __main__ -     eval_ppl = 2.45253\n","02/22/2024 09:45:38 - INFO - __main__ -     global_step = 24000\n","02/22/2024 09:45:38 - INFO - __main__ -     train_loss = 0.4746\n","02/22/2024 09:45:38 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 09:48:21 - INFO - __main__ -     bleu-4 = 22.95 \n","02/22/2024 09:48:21 - INFO - __main__ -     ********************\n","loss 0.4575:  50% 24998/50000 [4:56:34<3:47:23,  1.83it/s]02/22/2024 09:57:27 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 09:57:27 - INFO - __main__ -     Num examples = 580\n","02/22/2024 09:57:27 - INFO - __main__ -     Batch size = 16\n","02/22/2024 09:57:33 - INFO - __main__ -     eval_ppl = 2.50593\n","02/22/2024 09:57:33 - INFO - __main__ -     global_step = 25000\n","02/22/2024 09:57:33 - INFO - __main__ -     train_loss = 0.4575\n","02/22/2024 09:57:33 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:00:11 - INFO - __main__ -     bleu-4 = 22.37 \n","02/22/2024 10:00:11 - INFO - __main__ -     ********************\n","loss 0.4298:  52% 25998/50000 [5:08:24<3:39:28,  1.82it/s]02/22/2024 10:09:17 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 10:09:17 - INFO - __main__ -     Num examples = 580\n","02/22/2024 10:09:17 - INFO - __main__ -     Batch size = 16\n","02/22/2024 10:09:23 - INFO - __main__ -     eval_ppl = 2.49827\n","02/22/2024 10:09:23 - INFO - __main__ -     global_step = 26000\n","02/22/2024 10:09:23 - INFO - __main__ -     train_loss = 0.4298\n","02/22/2024 10:09:23 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:11:59 - INFO - __main__ -     bleu-4 = 23.33 \n","02/22/2024 10:11:59 - INFO - __main__ -     ********************\n","loss 0.4243:  54% 26998/50000 [5:20:13<3:29:34,  1.83it/s]02/22/2024 10:21:06 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 10:21:06 - INFO - __main__ -     Num examples = 580\n","02/22/2024 10:21:06 - INFO - __main__ -     Batch size = 16\n","02/22/2024 10:21:12 - INFO - __main__ -     eval_ppl = 2.56134\n","02/22/2024 10:21:12 - INFO - __main__ -     global_step = 27000\n","02/22/2024 10:21:12 - INFO - __main__ -     train_loss = 0.4243\n","02/22/2024 10:21:12 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:23:50 - INFO - __main__ -     bleu-4 = 21.55 \n","02/22/2024 10:23:50 - INFO - __main__ -     ********************\n","loss 0.4088:  56% 27998/50000 [5:32:03<3:20:15,  1.83it/s]02/22/2024 10:32:56 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 10:32:56 - INFO - __main__ -     Num examples = 580\n","02/22/2024 10:32:56 - INFO - __main__ -     Batch size = 16\n","02/22/2024 10:33:02 - INFO - __main__ -     eval_ppl = 2.55086\n","02/22/2024 10:33:02 - INFO - __main__ -     global_step = 28000\n","02/22/2024 10:33:02 - INFO - __main__ -     train_loss = 0.4088\n","02/22/2024 10:33:02 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:35:39 - INFO - __main__ -     bleu-4 = 24.13 \n","02/22/2024 10:35:39 - INFO - __main__ -     ********************\n","02/22/2024 10:35:39 - INFO - __main__ -     Best bleu:24.13\n","02/22/2024 10:35:39 - INFO - __main__ -     ********************\n","loss 0.3819:  58% 28998/50000 [5:43:57<3:10:29,  1.84it/s]02/22/2024 10:44:50 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 10:44:50 - INFO - __main__ -     Num examples = 580\n","02/22/2024 10:44:50 - INFO - __main__ -     Batch size = 16\n","02/22/2024 10:44:56 - INFO - __main__ -     eval_ppl = 2.59051\n","02/22/2024 10:44:56 - INFO - __main__ -     global_step = 29000\n","02/22/2024 10:44:56 - INFO - __main__ -     train_loss = 0.3819\n","02/22/2024 10:44:56 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:47:31 - INFO - __main__ -     bleu-4 = 21.69 \n","02/22/2024 10:47:31 - INFO - __main__ -     ********************\n","loss 0.374:  60% 29998/50000 [5:55:43<3:02:49,  1.82it/s] 02/22/2024 10:56:36 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 10:56:36 - INFO - __main__ -     Num examples = 580\n","02/22/2024 10:56:36 - INFO - __main__ -     Batch size = 16\n","02/22/2024 10:56:42 - INFO - __main__ -     eval_ppl = 2.5764\n","02/22/2024 10:56:42 - INFO - __main__ -     global_step = 30000\n","02/22/2024 10:56:42 - INFO - __main__ -     train_loss = 0.374\n","02/22/2024 10:56:42 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 10:59:26 - INFO - __main__ -     bleu-4 = 22.62 \n","02/22/2024 10:59:26 - INFO - __main__ -     ********************\n","loss 0.3578:  62% 30998/50000 [6:07:39<2:52:58,  1.83it/s]02/22/2024 11:08:32 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 11:08:32 - INFO - __main__ -     Num examples = 580\n","02/22/2024 11:08:32 - INFO - __main__ -     Batch size = 16\n","02/22/2024 11:08:39 - INFO - __main__ -     eval_ppl = 2.59021\n","02/22/2024 11:08:39 - INFO - __main__ -     global_step = 31000\n","02/22/2024 11:08:39 - INFO - __main__ -     train_loss = 0.3578\n","02/22/2024 11:08:39 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 11:11:16 - INFO - __main__ -     bleu-4 = 22.99 \n","02/22/2024 11:11:16 - INFO - __main__ -     ********************\n","loss 0.3461:  64% 31998/50000 [6:19:29<2:43:22,  1.84it/s]02/22/2024 11:20:22 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 11:20:22 - INFO - __main__ -     Num examples = 580\n","02/22/2024 11:20:22 - INFO - __main__ -     Batch size = 16\n","02/22/2024 11:20:28 - INFO - __main__ -     eval_ppl = 2.68233\n","02/22/2024 11:20:28 - INFO - __main__ -     global_step = 32000\n","02/22/2024 11:20:28 - INFO - __main__ -     train_loss = 0.3461\n","02/22/2024 11:20:28 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 11:23:00 - INFO - __main__ -     bleu-4 = 23.0 \n","02/22/2024 11:23:00 - INFO - __main__ -     ********************\n","loss 0.3246:  66% 32998/50000 [6:31:13<2:35:02,  1.83it/s]02/22/2024 11:32:06 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 11:32:06 - INFO - __main__ -     Num examples = 580\n","02/22/2024 11:32:06 - INFO - __main__ -     Batch size = 16\n","02/22/2024 11:32:13 - INFO - __main__ -     eval_ppl = 2.62176\n","02/22/2024 11:32:13 - INFO - __main__ -     global_step = 33000\n","02/22/2024 11:32:13 - INFO - __main__ -     train_loss = 0.3246\n","02/22/2024 11:32:13 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 11:34:47 - INFO - __main__ -     bleu-4 = 22.26 \n","02/22/2024 11:34:47 - INFO - __main__ -     ********************\n","loss 0.3205:  68% 33998/50000 [6:43:01<2:25:57,  1.83it/s]02/22/2024 11:43:54 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 11:43:54 - INFO - __main__ -     Num examples = 580\n","02/22/2024 11:43:54 - INFO - __main__ -     Batch size = 16\n","02/22/2024 11:44:00 - INFO - __main__ -     eval_ppl = 2.65365\n","02/22/2024 11:44:00 - INFO - __main__ -     global_step = 34000\n","02/22/2024 11:44:00 - INFO - __main__ -     train_loss = 0.3205\n","02/22/2024 11:44:00 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 11:46:27 - INFO - __main__ -     bleu-4 = 23.71 \n","02/22/2024 11:46:27 - INFO - __main__ -     ********************\n","loss 0.3073:  70% 34998/50000 [6:54:39<2:16:56,  1.83it/s]02/22/2024 11:55:32 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 11:55:32 - INFO - __main__ -     Num examples = 580\n","02/22/2024 11:55:32 - INFO - __main__ -     Batch size = 16\n","02/22/2024 11:55:38 - INFO - __main__ -     eval_ppl = 2.68367\n","02/22/2024 11:55:38 - INFO - __main__ -     global_step = 35000\n","02/22/2024 11:55:38 - INFO - __main__ -     train_loss = 0.3073\n","02/22/2024 11:55:38 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 11:58:14 - INFO - __main__ -     bleu-4 = 24.56 \n","02/22/2024 11:58:14 - INFO - __main__ -     ********************\n","02/22/2024 11:58:14 - INFO - __main__ -     Best bleu:24.56\n","02/22/2024 11:58:14 - INFO - __main__ -     ********************\n","loss 0.2909:  72% 35998/50000 [7:06:30<2:07:30,  1.83it/s]02/22/2024 12:07:23 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 12:07:23 - INFO - __main__ -     Num examples = 580\n","02/22/2024 12:07:23 - INFO - __main__ -     Batch size = 16\n","02/22/2024 12:07:29 - INFO - __main__ -     eval_ppl = 2.67833\n","02/22/2024 12:07:29 - INFO - __main__ -     global_step = 36000\n","02/22/2024 12:07:29 - INFO - __main__ -     train_loss = 0.2909\n","02/22/2024 12:07:29 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 12:10:03 - INFO - __main__ -     bleu-4 = 23.47 \n","02/22/2024 12:10:03 - INFO - __main__ -     ********************\n","loss 0.2823:  74% 36998/50000 [7:18:16<1:58:24,  1.83it/s]02/22/2024 12:19:09 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 12:19:09 - INFO - __main__ -     Num examples = 580\n","02/22/2024 12:19:09 - INFO - __main__ -     Batch size = 16\n","02/22/2024 12:19:15 - INFO - __main__ -     eval_ppl = 2.71027\n","02/22/2024 12:19:15 - INFO - __main__ -     global_step = 37000\n","02/22/2024 12:19:15 - INFO - __main__ -     train_loss = 0.2823\n","02/22/2024 12:19:15 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 12:21:48 - INFO - __main__ -     bleu-4 = 22.22 \n","02/22/2024 12:21:48 - INFO - __main__ -     ********************\n","loss 0.2716:  76% 37998/50000 [7:30:02<1:50:17,  1.81it/s]02/22/2024 12:30:55 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 12:30:55 - INFO - __main__ -     Num examples = 580\n","02/22/2024 12:30:55 - INFO - __main__ -     Batch size = 16\n","02/22/2024 12:31:01 - INFO - __main__ -     eval_ppl = 2.70425\n","02/22/2024 12:31:01 - INFO - __main__ -     global_step = 38000\n","02/22/2024 12:31:01 - INFO - __main__ -     train_loss = 0.2716\n","02/22/2024 12:31:01 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 12:33:31 - INFO - __main__ -     bleu-4 = 22.93 \n","02/22/2024 12:33:31 - INFO - __main__ -     ********************\n","loss 0.2634:  78% 38998/50000 [7:41:43<1:40:16,  1.83it/s]02/22/2024 12:42:37 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 12:42:37 - INFO - __main__ -     Num examples = 580\n","02/22/2024 12:42:37 - INFO - __main__ -     Batch size = 16\n","02/22/2024 12:42:43 - INFO - __main__ -     eval_ppl = 2.76559\n","02/22/2024 12:42:43 - INFO - __main__ -     global_step = 39000\n","02/22/2024 12:42:43 - INFO - __main__ -     train_loss = 0.2634\n","02/22/2024 12:42:43 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 12:45:11 - INFO - __main__ -     bleu-4 = 21.24 \n","02/22/2024 12:45:11 - INFO - __main__ -     ********************\n","loss 0.2485:  80% 39998/50000 [7:53:24<1:30:54,  1.83it/s]02/22/2024 12:54:17 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 12:54:17 - INFO - __main__ -     Num examples = 580\n","02/22/2024 12:54:17 - INFO - __main__ -     Batch size = 16\n","02/22/2024 12:54:23 - INFO - __main__ -     eval_ppl = 2.74378\n","02/22/2024 12:54:23 - INFO - __main__ -     global_step = 40000\n","02/22/2024 12:54:23 - INFO - __main__ -     train_loss = 0.2485\n","02/22/2024 12:54:23 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 12:56:53 - INFO - __main__ -     bleu-4 = 21.54 \n","02/22/2024 12:56:53 - INFO - __main__ -     ********************\n","loss 0.2454:  82% 40998/50000 [8:05:05<1:21:50,  1.83it/s]02/22/2024 13:05:58 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 13:05:58 - INFO - __main__ -     Num examples = 580\n","02/22/2024 13:05:58 - INFO - __main__ -     Batch size = 16\n","02/22/2024 13:06:04 - INFO - __main__ -     eval_ppl = 2.78289\n","02/22/2024 13:06:04 - INFO - __main__ -     global_step = 41000\n","02/22/2024 13:06:04 - INFO - __main__ -     train_loss = 0.2454\n","02/22/2024 13:06:04 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 13:08:36 - INFO - __main__ -     bleu-4 = 23.43 \n","02/22/2024 13:08:36 - INFO - __main__ -     ********************\n","loss 0.2352:  84% 41998/50000 [8:16:49<1:12:37,  1.84it/s]02/22/2024 13:17:42 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 13:17:42 - INFO - __main__ -     Num examples = 580\n","02/22/2024 13:17:42 - INFO - __main__ -     Batch size = 16\n","02/22/2024 13:17:48 - INFO - __main__ -     eval_ppl = 2.79123\n","02/22/2024 13:17:48 - INFO - __main__ -     global_step = 42000\n","02/22/2024 13:17:48 - INFO - __main__ -     train_loss = 0.2352\n","02/22/2024 13:17:48 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 13:20:25 - INFO - __main__ -     bleu-4 = 23.56 \n","02/22/2024 13:20:25 - INFO - __main__ -     ********************\n","loss 0.2242:  86% 42998/50000 [8:28:37<1:03:55,  1.83it/s]02/22/2024 13:29:30 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 13:29:30 - INFO - __main__ -     Num examples = 580\n","02/22/2024 13:29:30 - INFO - __main__ -     Batch size = 16\n","02/22/2024 13:29:36 - INFO - __main__ -     eval_ppl = 2.80375\n","02/22/2024 13:29:36 - INFO - __main__ -     global_step = 43000\n","02/22/2024 13:29:36 - INFO - __main__ -     train_loss = 0.2242\n","02/22/2024 13:29:36 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 13:32:05 - INFO - __main__ -     bleu-4 = 21.96 \n","02/22/2024 13:32:05 - INFO - __main__ -     ********************\n","loss 0.2212:  88% 43998/50000 [8:40:17<54:32,  1.83it/s]02/22/2024 13:41:10 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 13:41:10 - INFO - __main__ -     Num examples = 580\n","02/22/2024 13:41:10 - INFO - __main__ -     Batch size = 16\n","02/22/2024 13:41:16 - INFO - __main__ -     eval_ppl = 2.8136\n","02/22/2024 13:41:16 - INFO - __main__ -     global_step = 44000\n","02/22/2024 13:41:16 - INFO - __main__ -     train_loss = 0.2212\n","02/22/2024 13:41:16 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 13:43:48 - INFO - __main__ -     bleu-4 = 22.29 \n","02/22/2024 13:43:48 - INFO - __main__ -     ********************\n","loss 0.2125:  90% 44998/50000 [8:52:01<45:27,  1.83it/s]02/22/2024 13:52:54 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 13:52:54 - INFO - __main__ -     Num examples = 580\n","02/22/2024 13:52:54 - INFO - __main__ -     Batch size = 16\n","02/22/2024 13:53:01 - INFO - __main__ -     eval_ppl = 2.81898\n","02/22/2024 13:53:01 - INFO - __main__ -     global_step = 45000\n","02/22/2024 13:53:01 - INFO - __main__ -     train_loss = 0.2125\n","02/22/2024 13:53:01 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 13:55:37 - INFO - __main__ -     bleu-4 = 20.85 \n","02/22/2024 13:55:37 - INFO - __main__ -     ********************\n","loss 0.2083:  92% 45998/50000 [9:03:48<36:15,  1.84it/s]02/22/2024 14:04:41 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 14:04:41 - INFO - __main__ -     Num examples = 580\n","02/22/2024 14:04:41 - INFO - __main__ -     Batch size = 16\n","02/22/2024 14:04:48 - INFO - __main__ -     eval_ppl = 2.83824\n","02/22/2024 14:04:48 - INFO - __main__ -     global_step = 46000\n","02/22/2024 14:04:48 - INFO - __main__ -     train_loss = 0.2083\n","02/22/2024 14:04:48 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 14:07:19 - INFO - __main__ -     bleu-4 = 22.33 \n","02/22/2024 14:07:19 - INFO - __main__ -     ********************\n","loss 0.1992:  94% 46998/50000 [9:15:32<27:25,  1.82it/s]02/22/2024 14:16:25 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 14:16:25 - INFO - __main__ -     Num examples = 580\n","02/22/2024 14:16:25 - INFO - __main__ -     Batch size = 16\n","02/22/2024 14:16:31 - INFO - __main__ -     eval_ppl = 2.83186\n","02/22/2024 14:16:31 - INFO - __main__ -     global_step = 47000\n","02/22/2024 14:16:31 - INFO - __main__ -     train_loss = 0.1992\n","02/22/2024 14:16:31 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 14:19:08 - INFO - __main__ -     bleu-4 = 22.52 \n","02/22/2024 14:19:08 - INFO - __main__ -     ********************\n","loss 0.1997:  96% 47998/50000 [9:27:21<18:09,  1.84it/s]02/22/2024 14:28:14 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 14:28:14 - INFO - __main__ -     Num examples = 580\n","02/22/2024 14:28:14 - INFO - __main__ -     Batch size = 16\n","02/22/2024 14:28:20 - INFO - __main__ -     eval_ppl = 2.84403\n","02/22/2024 14:28:20 - INFO - __main__ -     global_step = 48000\n","02/22/2024 14:28:20 - INFO - __main__ -     train_loss = 0.1997\n","02/22/2024 14:28:20 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 14:30:52 - INFO - __main__ -     bleu-4 = 21.98 \n","02/22/2024 14:30:52 - INFO - __main__ -     ********************\n","loss 0.1961:  98% 48998/50000 [9:39:04<09:04,  1.84it/s]02/22/2024 14:39:57 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 14:39:57 - INFO - __main__ -     Num examples = 580\n","02/22/2024 14:39:57 - INFO - __main__ -     Batch size = 16\n","02/22/2024 14:40:04 - INFO - __main__ -     eval_ppl = 2.83182\n","02/22/2024 14:40:04 - INFO - __main__ -     global_step = 49000\n","02/22/2024 14:40:04 - INFO - __main__ -     train_loss = 0.1961\n","02/22/2024 14:40:04 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 14:42:38 - INFO - __main__ -     bleu-4 = 23.44 \n","02/22/2024 14:42:38 - INFO - __main__ -     ********************\n","loss 0.1894: 100% 49998/50000 [9:50:51<00:01,  1.84it/s]02/22/2024 14:51:44 - INFO - __main__ -   \n","***** Running evaluation *****\n","02/22/2024 14:51:44 - INFO - __main__ -     Num examples = 580\n","02/22/2024 14:51:44 - INFO - __main__ -     Batch size = 16\n","02/22/2024 14:51:50 - INFO - __main__ -     eval_ppl = 2.83622\n","02/22/2024 14:51:50 - INFO - __main__ -     global_step = 50000\n","02/22/2024 14:51:50 - INFO - __main__ -     train_loss = 0.1894\n","02/22/2024 14:51:50 - INFO - __main__ -     ********************\n","Total: 580\n","02/22/2024 14:54:25 - INFO - __main__ -     bleu-4 = 23.1 \n","02/22/2024 14:54:25 - INFO - __main__ -     ********************\n","loss 0.2846: 100% 50000/50000 [9:53:33<00:00,  1.40it/s]\n","\u001b[?2004h\u001b[01;34m/content/drive/MyDrive/logicalErrorFix-1\u001b[00m# "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2I5zv8fMmkIK","executionInfo":{"status":"ok","timestamp":1708618970736,"user_tz":-540,"elapsed":9924,"user":{"displayName":"__.__-__-_____","userId":"05049812847516276753"}},"outputId":"81b16e61-e8e4-4c4b-a9b5-9304c2874cf8"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!bash"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zigkykRKmh3m","outputId":"71b3566f-0286-42f5-b6e0-e7ba0583c7a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["bash: cannot set terminal process group (775): Inappropriate ioctl for device\n","bash: no job control in this shell\n","\u001b[?2004h\u001b[01;34m/content\u001b[00m# cd \n","\u001b[?2004h\u001b[01;34m~\u001b[00m# /content/drive/MyDrive/logicalErrorFix-1\n","bash: /content/drive/MyDrive/logicalErrorFix-1: Is a directory\n","\u001b[?2004h\u001b[01;34m~\u001b[00m# cd /content/drive/MyDrive/logicalErrorFix-1\n","\u001b[?2004h\u001b[01;34m/content/drive/MyDrive/logicalErrorFix-1\u001b[00m# bash eval.sh\n","02/22/2024 16:23:28 - INFO - numexpr.utils -   NumExpr defaulting to 2 threads.\n","02/22/2024 16:23:28 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/cpp', load_model_path='model/cpp/checkpoint-best-bleu/pytorch_model.bin', train_filename=None, dev_filename='./data/edit_distance/pair_code_edit_dist_valid.txt', test_filename='./data/edit_distance/pair_code_edit_dist_test.txt', config_name='', tokenizer_name='', max_source_length=512, max_target_length=64, do_train=False, do_eval=False, do_test=True, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=128, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=-1, train_steps=-1, warmup_steps=0, local_rank=-1, seed=42)\n","02/22/2024 16:23:28 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False\n","config.json: 100% 498/498 [00:00<00:00, 2.85MB/s]\n","tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 154kB/s]\n","vocab.json: 100% 899k/899k [00:00<00:00, 4.75MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 7.27MB/s]\n","special_tokens_map.json: 100% 150/150 [00:00<00:00, 995kB/s]\n","pytorch_model.bin: 100% 499M/499M [00:04<00:00, 116MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","02/22/2024 16:23:36 - INFO - __main__ -   reload model from model/cpp/checkpoint-best-bleu/pytorch_model.bin\n","02/22/2024 16:23:43 - INFO - __main__ -   Test file: ./data/edit_distance/pair_code_edit_dist_test.txt\n","  0% 0/7 [00:00<?, ?it/s]/content/drive/MyDrive/logicalErrorFix-1/model.py:77: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)\n","  zero=torch.cuda.LongTensor(1).fill_(0)\n","2024-02-22 16:25:03.726338: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-22 16:25:03.726398: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-22 16:25:03.727859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-02-22 16:25:05.329446: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","100% 7/7 [08:51<00:00, 75.87s/it]\n","Total: 861\n","02/22/2024 16:32:37 - INFO - __main__ -     bleu-4 = 23.45 \n","02/22/2024 16:32:37 - INFO - __main__ -     ********************\n","\u001b[?2004h\u001b[01;34m/content/drive/MyDrive/logicalErrorFix-1\u001b[00m# "]}]}]}